library(e1071) #library required for the naiveBayes function
library(caTools) #library required for the sample.split function
library(caret)
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Data Analytics\\Assignment 2 - (naive basis)")
diabetes <- read.csv("PimaIndiansDiabetes.csv")
head(diabetes)
diabetes_split <- sample.split(diabetes, SplitRatio = 0.9) #splitting it into training and test data in ratio 0.9
diabetes_train <- subset(diabetes, diabetes_split == TRUE)
diabetes_test <- subset(diabetes, diabetes_split == FALSE)
nb_default <- naiveBayes(Outcome~.,data = diabetes_train) #training the model with training data to predict the class lable taking all other attributes into consideration
nb_predict <- predict(nb_default, newdata = diabetes_test, "raw") #applying the trained model on test data
highest_prob <- as.factor(colnames(nb_predict)[apply(nb_predict, 1, which.max)]) #applying appropriate label based on predicted values
table(highestprob, diabetes_test[,9]) #displaying table of predicted outcome vs actual outcome
table(highestprob)
table(diabetes_test[,9])
png(file = "pie90-10.png")
labs <- c("No diabetes","Diabetes")
pie(table(highestprob),labels = labs)
library(e1071) #library required for the naiveBayes function
library(caTools) #library required for the sample.split function
library(caret)
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Data Analytics\\Assignment 2 - (naive basis)")
diabetes <- read.csv("PimaIndiansDiabetes.csv")
head(diabetes)
diabetes_split <- sample.split(diabetes, SplitRatio = 0.9) #splitting it into training and test data in ratio 0.9
diabetes_train <- subset(diabetes, diabetes_split == TRUE)
diabetes_test <- subset(diabetes, diabetes_split == FALSE)
nb_default <- naiveBayes(Outcome~.,data = diabetes_train) #training the model with training data to predict the class lable taking all other attributes into consideration
nb_predict <- predict(nb_default, newdata = diabetes_test, "raw") #applying the trained model on test data
highest_prob <- as.factor(colnames(nb_predict)[apply(nb_predict, 1, which.max)]) #applying appropriate label based on predicted values
table(highestprob, diabetes_test[,9]) #displaying table of predicted outcome vs actual outcome
table(highestprob)
table(diabetes_test[,9])
png(file = "pie90-10.png")
labs <- c("No diabetes","Diabetes")
pie(table(highestprob),labels = labs)
dev.off()
pie(table(highestprob),labels = labs)
library(e1071) #library required for the naiveBayes function
library(caTools) #library required for the sample.split function
library(caret)
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Data Analytics\\Assignment 2 - (naive basis)")
diabetes <- read.csv("PimaIndiansDiabetes.csv")
head(diabetes)
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Data Analytics\\Assignment 2 - (naive basis)")
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Data Analytics\\Assignment 2 - (naive basis)\\R")
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Data Analytics\\Assignment 2 - naive bayes\\R")
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Lab Practise 1\\Data Analytics\\Assignment 2 - naive bayes\\R")
library(e1071) #library required for the naiveBayes function
library(caTools) #library required for the sample.split function
library(caret)
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Lab Practise 1\\Data Analytics\\Assignment 2 - naive bayes\\R")
diabetes <- read.csv("PimaIndiansDiabetes.csv")
head(diabetes)
diabetes_split <- sample.split(diabetes, SplitRatio = 0.9) #splitting it into training and test data in ratio 0.9
diabetes_train <- subset(diabetes, diabetes_split == TRUE)
diabetes_test <- subset(diabetes, diabetes_split == FALSE)
nb_default <- naiveBayes(Outcome~.,data = diabetes_train) #training the model with training data to predict the class lable taking all other attributes into consideration
View(diabetes_train)
View(diabetes_train)
nb_default <- naiveBayes(Class~.,data = diabetes_train) #training the model with training data to predict the class lable taking all other attributes into consideration
View(nb_default)
nb_predict <- predict(nb_default, newdata = diabetes_test, "raw") #applying the trained model on test data
View(nb_predict)
highest_prob <- as.factor(colnames(nb_predict)[apply(nb_predict, 1, which.max)]) #applying appropriate label based on predicted values
table(highestprob, diabetes_test[,9]) #displaying table of predicted outcome vs actual outcome
table(highest_prob, diabetes_test[,9]) #displaying table of predicted outcome vs actual outcome
table(highest_prob)
table(diabetes_test[,9])
png(file = "pie90-10.png")
labs <- c("No diabetes","Diabetes")
pie(table(highest_prob),labels = labs)
dev.off()
library(rpart) #library required for decision tree
library(caTools)
library(e1071)
library(rattle)
library(rpart.plot) #library required for plotting the decision tree
library(RColorBrewer)
library(rpart) #library required for decision tree
library(caTools)
library(e1071)
library(rpart.plot) #library required for plotting the decision tree
library(RColorBrewer)
data <- read.csv('201805-capitalbikeshare-tripdata.csv')
#install.packages("rattle", dependencies = TRUE, repos='http://cran.rstudio.com/')
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Lab Practise 1\\Data Analytics\\Assignment 4 - decision tree\\R")
data <- read.csv('201805-capitalbikeshare-tripdata.csv')
data <- read.csv('2010-capitalbikeshare-tripdata.csv')
# To display number of rows and columns in data
dim(data)
set.seed(123)
my_sample <- sample.split(data, SplitRatio = 0.8) #creating a sample
biker_train <- data[my_sample, c(1,4,6,9)] #training data containing the sample and 4 specific columns
biker_test <- data[!my_sample, c(1,4,6,9)]
summary(biker_test)
summary(biker_train)
fit <- rpart(biker_train$Member.type~., data = biker_train, method = "class") #building decision tree model based on training data to predict Member Type on the basis of all other attributes
fit
fancyRpartPlot(fit)
rpart.plot(fit)
rpart.plot(fit,type=4,extra=101)
prediction <- predict(fit,newdata = bikerTest[,-4],type = ("class")) #making predicions on test data using the model made
prediction <- predict(fit,newdata = biker_test[,-4],type = ("class")) #making predicions on test data using the model made
table(biker_test[,4],prediction) #table comparing predicted type with actual type
table(prediction)
#recall_accuracy(bikerTest[,4],prediction)
png(file="trypie.png")
labs <- c("Member","Casual")
pie(table(prediction),labels = labs)
dev.off()
confusionMatrix(prediction,biker_test[,4])
dev.off()
library(data.table) # used for fread
library(plyr) # used for laply
library(stringr) # used for str_replace_all
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Lab Practise 1\\Data Analytics\\mini project - tweeter sentiment analysis\\R")
system.time( data <- fread(file = "Tweets.csv" , header = TRUE , sep = "," ) )
if ( TRUE ) {
neg <- scan("negative-words.txt", what="character", comment.char=";")
pos <- scan("positive-words.txt", what="character", comment.char=";")
colnames(data)[3] <- "tweet"
score.sentiment = function(tweets, pos.words, neg.words)
{
require(plyr)
require(stringr)
scores = laply(tweets, function(tweet, pos.words, neg.words) {
tweet = gsub('https://','',tweet) # removes https://
tweet = gsub('http://','',tweet) # removes http://
tweet=gsub('[^[:graph:]]', ' ',tweet) ## removes graphic characters
#like emoticons
tweet = gsub('[[:punct:]]', '', tweet) # removes punctuation
tweet = gsub('[[:cntrl:]]', '', tweet) # removes control characters
tweet = gsub('\\d+', '', tweet) # removes numbers
tweet=str_replace_all(tweet,"[^[:graph:]]", " ")
tweet = tolower(tweet) # makes all letters lowercase
word.list = str_split(tweet, '\\s+') # splits the tweets by word in a list
words = unlist(word.list) # turns the list into vector
pos.matches = match(words, pos.words) ## returns matching
#values for words from list
neg.matches = match(words, neg.words)
pos.matches = !is.na(pos.matches) ## converts matching values to true of false
neg.matches = !is.na(neg.matches)
score = sum(pos.matches) - sum(neg.matches) # true and false are
#treated as 1 and 0 so they can be added
return(score)
}, pos.words, neg.words )
scores.df = data.frame(score=scores, text=tweets)
return(scores.df)
}
analysis = score.sentiment(data$tweet, pos, neg) # calls sentiment function
png(filename = "Histogram.png")
hist(analysis$score , main = "Histogram Of Sentiment Scores" , xlab = "Sentiment Values" , ylab = "Number Of Tweets")
dev.off();
analysis[ analysis$score > 0 , 1 ] = 1
analysis[ analysis$score < 0 , 1 ] = -1
table(analysis$score)
}
