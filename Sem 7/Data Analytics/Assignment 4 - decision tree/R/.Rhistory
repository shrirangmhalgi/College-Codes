library(e1071) #library required for the naiveBayes function
library(caTools) #library required for the sample.split function
library(caret)
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Data Analytics\\Assignment 2 - (naive basis)")
diabetes <- read.csv("PimaIndiansDiabetes.csv")
head(diabetes)
diabetes_split <- sample.split(diabetes, SplitRatio = 0.9) #splitting it into training and test data in ratio 0.9
diabetes_train <- subset(diabetes, diabetes_split == TRUE)
diabetes_test <- subset(diabetes, diabetes_split == FALSE)
nb_default <- naiveBayes(Outcome~.,data = diabetes_train) #training the model with training data to predict the class lable taking all other attributes into consideration
nb_predict <- predict(nb_default, newdata = diabetes_test, "raw") #applying the trained model on test data
highest_prob <- as.factor(colnames(nb_predict)[apply(nb_predict, 1, which.max)]) #applying appropriate label based on predicted values
table(highestprob, diabetes_test[,9]) #displaying table of predicted outcome vs actual outcome
table(highestprob)
table(diabetes_test[,9])
png(file = "pie90-10.png")
labs <- c("No diabetes","Diabetes")
pie(table(highestprob),labels = labs)
library(e1071) #library required for the naiveBayes function
library(caTools) #library required for the sample.split function
library(caret)
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Data Analytics\\Assignment 2 - (naive basis)")
diabetes <- read.csv("PimaIndiansDiabetes.csv")
head(diabetes)
diabetes_split <- sample.split(diabetes, SplitRatio = 0.9) #splitting it into training and test data in ratio 0.9
diabetes_train <- subset(diabetes, diabetes_split == TRUE)
diabetes_test <- subset(diabetes, diabetes_split == FALSE)
nb_default <- naiveBayes(Outcome~.,data = diabetes_train) #training the model with training data to predict the class lable taking all other attributes into consideration
nb_predict <- predict(nb_default, newdata = diabetes_test, "raw") #applying the trained model on test data
highest_prob <- as.factor(colnames(nb_predict)[apply(nb_predict, 1, which.max)]) #applying appropriate label based on predicted values
table(highestprob, diabetes_test[,9]) #displaying table of predicted outcome vs actual outcome
table(highestprob)
table(diabetes_test[,9])
png(file = "pie90-10.png")
labs <- c("No diabetes","Diabetes")
pie(table(highestprob),labels = labs)
dev.off()
pie(table(highestprob),labels = labs)
library(e1071) #library required for the naiveBayes function
library(caTools) #library required for the sample.split function
library(caret)
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Data Analytics\\Assignment 2 - (naive basis)")
diabetes <- read.csv("PimaIndiansDiabetes.csv")
head(diabetes)
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Data Analytics\\Assignment 2 - (naive basis)")
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Data Analytics\\Assignment 2 - (naive basis)\\R")
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Data Analytics\\Assignment 2 - naive bayes\\R")
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Lab Practise 1\\Data Analytics\\Assignment 2 - naive bayes\\R")
library(e1071) #library required for the naiveBayes function
library(caTools) #library required for the sample.split function
library(caret)
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Lab Practise 1\\Data Analytics\\Assignment 2 - naive bayes\\R")
diabetes <- read.csv("PimaIndiansDiabetes.csv")
head(diabetes)
diabetes_split <- sample.split(diabetes, SplitRatio = 0.9) #splitting it into training and test data in ratio 0.9
diabetes_train <- subset(diabetes, diabetes_split == TRUE)
diabetes_test <- subset(diabetes, diabetes_split == FALSE)
nb_default <- naiveBayes(Outcome~.,data = diabetes_train) #training the model with training data to predict the class lable taking all other attributes into consideration
View(diabetes_train)
View(diabetes_train)
nb_default <- naiveBayes(Class~.,data = diabetes_train) #training the model with training data to predict the class lable taking all other attributes into consideration
View(nb_default)
nb_predict <- predict(nb_default, newdata = diabetes_test, "raw") #applying the trained model on test data
View(nb_predict)
highest_prob <- as.factor(colnames(nb_predict)[apply(nb_predict, 1, which.max)]) #applying appropriate label based on predicted values
table(highestprob, diabetes_test[,9]) #displaying table of predicted outcome vs actual outcome
table(highest_prob, diabetes_test[,9]) #displaying table of predicted outcome vs actual outcome
table(highest_prob)
table(diabetes_test[,9])
png(file = "pie90-10.png")
labs <- c("No diabetes","Diabetes")
pie(table(highest_prob),labels = labs)
dev.off()
library(rpart) #library required for decision tree
library(caTools)
library(e1071)
library(rattle)
library(rpart.plot) #library required for plotting the decision tree
library(RColorBrewer)
library(rpart) #library required for decision tree
library(caTools)
library(e1071)
library(rpart.plot) #library required for plotting the decision tree
library(RColorBrewer)
data <- read.csv('201805-capitalbikeshare-tripdata.csv')
#install.packages("rattle", dependencies = TRUE, repos='http://cran.rstudio.com/')
setwd("C:\\Users\\DELL\\Desktop\\Sem 7 submissions\\Lab Practise 1\\Data Analytics\\Assignment 4 - decision tree\\R")
data <- read.csv('201805-capitalbikeshare-tripdata.csv')
data <- read.csv('2010-capitalbikeshare-tripdata.csv')
# To display number of rows and columns in data
dim(data)
set.seed(123)
my_sample <- sample.split(data, SplitRatio = 0.8) #creating a sample
biker_train <- data[my_sample, c(1,4,6,9)] #training data containing the sample and 4 specific columns
biker_test <- data[!my_sample, c(1,4,6,9)]
summary(biker_test)
summary(biker_train)
fit <- rpart(biker_train$Member.type~., data = biker_train, method = "class") #building decision tree model based on training data to predict Member Type on the basis of all other attributes
fit
fancyRpartPlot(fit)
rpart.plot(fit)
rpart.plot(fit,type=4,extra=101)
prediction <- predict(fit,newdata = bikerTest[,-4],type = ("class")) #making predicions on test data using the model made
prediction <- predict(fit,newdata = biker_test[,-4],type = ("class")) #making predicions on test data using the model made
table(biker_test[,4],prediction) #table comparing predicted type with actual type
table(prediction)
#recall_accuracy(bikerTest[,4],prediction)
png(file="trypie.png")
labs <- c("Member","Casual")
pie(table(prediction),labels = labs)
dev.off()
confusionMatrix(prediction,biker_test[,4])
dev.off()
